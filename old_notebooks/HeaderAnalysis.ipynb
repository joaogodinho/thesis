{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-30d86b36e3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloadHeadersCSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ..lib.data_loading import loadHeadersCSV\n",
    "from ..lib.plotting import *\n",
    "from ..lib.helpers import *\n",
    "\n",
    "# Build all other dataframes from this one\n",
    "headers = loadHeadersCSV('data/header_analyses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Monthly count for all samples\n",
    "monthly_count = headers.md5.resample('M').count()\n",
    "monthly_count = monthly_count.rename('All samples')\n",
    "plotByMonth(monthly_count,\n",
    "            'monthly_count',\n",
    "            'Monthly Count ($\\mu$={:.0f}, $\\Sigma$={})'.format(monthly_count.mean(), monthly_count.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_count = headers.drop_duplicates(subset='md5').md5.resample('M').count().rename('Unique samples')\n",
    "duplicated_count = headers[headers.duplicated(subset='md5')].md5.resample('M').count().rename('Duplicated samples')\n",
    "print('Total number of unique analysis: {}'.format(unique_count.sum()))\n",
    "print('Total number of duplicated analysis: {}'.format(duplicated_count.sum()))\n",
    "dups_percent = pd.concat([unique_count, duplicated_count], axis=1)\n",
    "dups_percent = dups_percent.divide(dups_percent.sum(axis=1), axis=0)\n",
    "plotByMonthPercentage(dups_percent, 'dups_percent', 'Unique vs duplicated samples by percentage (MD5 unique)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert unique_count.sum() + duplicated_count.sum() == len(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Distribution of file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Different file types scanned\n",
    "file_types = headers.file_type.unique()\n",
    "print('Total unique file types: {}\\n'.format(len(file_types)))\n",
    "# for t in sorted(file_types):\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The high number of file types can be easily explained by looking at the types list. Many of the types result to the same general type, but differ due to factors like versioning, size (for images) and encoding.\n",
    "\n",
    "## Executables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some ELF/Mach-O files are not caught by \"executable\" filter, added manually\n",
    "exec_crit = headers.file_type.map(lambda x: 'executable' in x.lower() or x.startswith('ELF') or x.startswith('Mach-O'))\n",
    "exec_types = sorted(headers.file_type[exec_crit].unique())\n",
    "print('Total unique file types with \"executable\": {}\\n'.format(len(exec_types)))\n",
    "for t in exec_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Windows Portable Executables (32bit)\n",
    "These analysis *generally* contain both static and dynamic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pe32_types = list(filter(lambda x: x.startswith('PE32 '), exec_types))\n",
    "print('Total unique PE32 (32bit) types: {}\\n'.format(len(pe32_types)))\n",
    "for t in pe32_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Other architectures/platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "not_pe32_types = list(filter(lambda x: not x.startswith('PE32 '), exec_types))\n",
    "print('Total unique not PE32 (32bit) types: {}\\n'.format(len(not_pe32_types)))\n",
    "for t in not_pe32_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Text files\n",
    "\n",
    "This includes source files, scripts, html, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_keywords = ['text', 'foxpro']\n",
    "text_crit = headers.file_type.map(mapKeywords(text_keywords))\n",
    "# Exclude what was considered executable type\n",
    "text_types = sorted(headers.file_type[~exec_crit & text_crit].unique())\n",
    "print('Total unique file types with \"text\": {}\\n'.format(len(text_types)))\n",
    "for t in text_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Media (images, audio, video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "media_keywords = ['image', 'audio', 'video', 'mpeg', 'bitmap', 'icon resource']\n",
    "media_crit = headers.file_type.map(mapKeywords(media_keywords))\n",
    "media_types = sorted(headers.file_type[~exec_crit & ~text_crit & media_crit].unique())\n",
    "print('Total unique file types with {}: {}\\n'.format(media_keywords, len(media_types)))\n",
    "for t in media_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "arch_keywords = ['archive', 'compressed']\n",
    "arch_crit = headers.file_type.map(mapKeywords(arch_keywords))\n",
    "arch_types = sorted(headers.file_type[~exec_crit & ~text_crit & ~media_crit & arch_crit].unique())\n",
    "print('Total unique archive types: {}\\n'.format(len(arch_types)))\n",
    "for t in arch_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_keywords = ['pdf', 'microsoft ', 'composite document file', 'fdf document', 'opendocument']\n",
    "doc_crit = headers.file_type.map(mapKeywords(doc_keywords))\n",
    "doc_types = sorted(headers.file_type[~exec_crit & ~text_crit & ~media_crit & ~arch_crit & doc_crit].unique())\n",
    "print('Total unique document types: {}\\n'.format(len(doc_types)))\n",
    "for t in doc_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Remaining types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Used to tune the previous sections for missing types\n",
    "other_types = sorted(headers.file_type[~exec_crit & ~text_crit & ~media_crit & ~arch_crit & ~doc_crit].unique())\n",
    "print('Total unique remaining types: {}\\n'.format(len(other_types)))\n",
    "for t in other_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "exec_count = headers[exec_crit].drop_duplicates(subset='md5').md5.resample('M').count().rename('Executables')\n",
    "text_count = headers[text_crit].drop_duplicates(subset='md5').md5.resample('M').count().rename('Text files')\n",
    "media_count = headers[media_crit].drop_duplicates(subset='md5').md5.resample('M').count().rename('Media')\n",
    "arch_count = headers[arch_crit].drop_duplicates(subset='md5').md5.resample('M').count().rename('Archives')\n",
    "doc_count = headers[doc_crit].drop_duplicates(subset='md5').md5.resample('M').count().rename('Documents')\n",
    "other_count = headers[~exec_crit & ~text_crit & ~media_crit & ~arch_crit & ~doc_crit].drop_duplicates(subset='md5').md5.resample('M').count().rename('Other')\n",
    "\n",
    "monthly_percent = pd.concat([exec_count, doc_count, arch_count, text_count, other_count, media_count], axis=1)\n",
    "monthly_percent = monthly_percent.divide(monthly_percent.sum(axis=1), axis=0)\n",
    "plotByMonthPercentage(monthly_percent, 'monthly_percent_unique', 'File types by percentage (only unique MD5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert len(file_types) == len(exec_types) + len(text_types) + len(media_types) + len(doc_types) + len(arch_types) + len(other_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Antivirus Classification\n",
    "\n",
    "The amount of vendors varies throughout the time, hence the choice of normalizing by dividing the positive classifications by the total amount of vendors at the time of the analysis.\n",
    "\n",
    "The following accounts only for unique samples, for duplicated samples only the last analysis is taken into account. Samples that were unknown in VirusTotal are given a value of -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Keeping this in a separate cell, since it takes 'some' time to exec\n",
    "av_col = headers.drop_duplicates(subset='md5', keep='last').antivirus\n",
    "av_col = av_col.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "av_col_known = av_col[av_col != -1]\n",
    "av_col_unknown = av_col[av_col == -1]\n",
    "print('Number of known (in VirusTotal) samples:\\t{}'.format(av_col_known.count()))\n",
    "print('Number of unknown samples:\\t\\t\\t{}'.format(av_col_unknown.count()))\n",
    "print('Mean for known samples:\\t\\t\\t\\t{:.2f}'.format(av_col_known.mean()))\n",
    "print('Standard deviation for known samples:\\t\\t{:.2f}'.format(av_col_known.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The main problem now is defining the threshold that classifies a sample as malware.\n",
    "\n",
    "The following values may need tweaking..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NOTMAL_THR = 0.1\n",
    "MAL_THR = 0.3\n",
    "av_col_notmal = av_col_known[av_col_known < NOTMAL_THR]\n",
    "av_col_mal = av_col_known[av_col_known > MAL_THR]\n",
    "av_col_grey = av_col_known[(NOTMAL_THR <= av_col_known) & (av_col_known <= MAL_THR)]\n",
    "print('Malware:\\t{} ({:.2f})'.format(av_col_mal.count(), av_col_mal.count()/av_col_known.count()))\n",
    "print('Not malware:\\t{} ({:.2f})'.format(av_col_notmal.count(), av_col_notmal.count()/av_col_known.count()))\n",
    "print('Grey area:\\t{} ({:.2f})'.format(av_col_grey.count(), av_col_grey.count()/av_col_known.count()))\n",
    "\n",
    "# Sanity check\n",
    "assert len(av_col_known) == len(av_col_notmal) + len(av_col_mal) + len(av_col_grey)\n",
    "\n",
    "av_col_notmal = av_col_notmal.resample('M').count().rename('Not malware [0, {})'.format(NOTMAL_THR))\n",
    "av_col_mal = av_col_mal.resample('M').count().rename('Malware ({}, 1]'.format(MAL_THR))\n",
    "av_col_grey = av_col_grey.resample('M').count().rename('Grey area [{}, {}]'.format(NOTMAL_THR, MAL_THR))\n",
    "\n",
    "malware_percent = pd.concat([av_col_mal, av_col_grey, av_col_notmal], axis=1)\n",
    "malware_percent = malware_percent.divide(malware_percent.sum(axis=1), axis=0)\n",
    "plotByMonthPercentage(malware_percent, 'malware_percent', 'Samples classified as malware by percentage (only unique MD5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evolution in duplicated samples\n",
    "\n",
    "How long until an unknown sample becomes known?\n",
    "\n",
    "Do samples tend to increase or decrease in classification (i.e. false positive rate, false negative)?\n",
    "\n",
    "How much time do vendors take to identify new malware (i.e. time from 0.0 to some threshold)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dups_class = headers.copy()\n",
    "dups_class['index'] = dups_class.index\n",
    "# Apply the normalization again, to facilitate filtering\n",
    "dups_class['antivirus'] = dups_class['antivirus'].apply(normalize)\n",
    "# Keep only duplicated samples that changed the antivirus classification\n",
    "dups_class = dups_class.drop_duplicates(['md5', 'antivirus'])\n",
    "# Keep only duplicated that changed in time, don't have access to the fulltimestamp, hence same day samples\n",
    "# won't be helpful\n",
    "# dups_class = dups_class.drop_duplicates(['md5', 'index'], keep='last')\n",
    "# Keep only duplicates\n",
    "dups_class = dups_class[dups_class.duplicated(subset='md5', keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### From unknown to known\n",
    "\n",
    "Check how much time it takes for a sample to go from unknown to known, this doesn't take into account if the sample is actually malware or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If the first submission was unknown (-1), calculate the time it took until\n",
    "# sample became known.\n",
    "def unknown_to_known(sample):\n",
    "    if sample[0] == -1:\n",
    "        for idx, val in enumerate(sample[1:]):\n",
    "            if val != -1:\n",
    "                # We take the average between the submission when the sample was known and the\n",
    "                # submission before that, to give the vendors some slack\n",
    "                # + 1 because we're enumerating from [1:]\n",
    "                avg_days = (sample.index[idx + 1] - sample.index[idx]).days / 2\n",
    "                return (sample.index[idx + 1] - sample.index[0]).days - avg_days\n",
    "    else:\n",
    "        return -1.0\n",
    "        \n",
    "dups_unk_to_k = dups_class.groupby('md5').agg({'antivirus': unknown_to_known}).antivirus.rename('days')\n",
    "dups_unk_to_k = (dups_unk_to_k[dups_unk_to_k.map(lambda x: x != -1)]).astype(int)\n",
    "\n",
    "print('Mean (in days) for a sample to become known:\\t{:.2f}'.format(dups_unk_to_k.mean()))\n",
    "print('Median for a sample to become known:\\t\\t{:.2f}'.format(dups_unk_to_k.median()))\n",
    "print('Standard deviation (in days):\\t\\t\\t{:.2f}'.format(dups_unk_to_k.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One must take into account that the only available information is from malwr.com, which means samples may become known sooner, but one only knows after the sample has been resubmitted.\n",
    "\n",
    "### Tendency in the classification\n",
    "\n",
    "Check if the tendency for duplicated samples is to increase or decrease, in terms of classification.\n",
    "\n",
    "Given that the classification results are only shown for vendors that have seen the sample, an upward tendency reflects a false negative tendency, while a downward tendency indicates a false positive tendency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculates the tendency for a given sample, based on duplicated submissions\n",
    "# Returns 1 for positive tendency (later submissions have higher classification)\n",
    "# Returns -1 for negative tendency (later submissions have lower classification)\n",
    "# Returns 0 for no tendency (classification between submissions doesn't go above a threshold)\n",
    "# Returns -2 if there aren't enough submissions to check for a tendency\n",
    "def tendency(sample):\n",
    "    from functools import reduce\n",
    "    # If the submissions didn't vary by more than this threshold, no tendency\n",
    "    CHANGE_THR = 0.05\n",
    "    values = []\n",
    "    \n",
    "    for idx, val in sample.iteritems():\n",
    "        if val != -1:\n",
    "            values.append(val)\n",
    "    # Not enough values to check for tendency\n",
    "    if len(values) < 2:\n",
    "        return -2\n",
    "    \n",
    "    diff = [y - x for x, y in zip(values, values[1:])]\n",
    "    # The mean variation is above the threshold\n",
    "    if reduce(lambda x, y: abs(x) + abs(y), diff)/len(diff) > CHANGE_THR:\n",
    "        pos = sum(x > 0 for x in diff)\n",
    "        neg = sum(x < 0 for x in diff)\n",
    "        return 1 if pos > neg else -1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "dups_tendency = dups_class.groupby('md5').agg({'antivirus': tendency}).antivirus.rename('tendency').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_tend = dups_tendency[dups_tendency == 1]\n",
    "neg_tend = dups_tendency[dups_tendency == -1]\n",
    "\n",
    "print('Number of submissions with positive tendency: {} ({:.2f})'.format(pos_tend.count(), pos_tend.count()/dups_tendency.count()))\n",
    "print('Number of submissions with negative tendency: {} ({:.2f})'.format(neg_tend.count(), neg_tend.count()/dups_tendency.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The positive tendency for over 50% of duplicated samples shows that vendors do prefer to classify\n",
    "\n",
    "that the sample takes some time to propagate between vendors, while the negative tendency around 2% reflects a low false positive rate correction, meaning that vendors do not tend to unclassify a sample as malware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Average time to classify a malware\n",
    "\n",
    "How much time does it take for a sample to go from \"not malware\" to \"malware\". Assuming the previous threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate the days it took for a sample go from below the threshold\n",
    "# to above the malware threshold. Only includes samples that were known but\n",
    "# not classified as malware\n",
    "def zero_to_malware(sample):\n",
    "    if 0 <= sample[0] < NOTMAL_THR:\n",
    "        for idx, val in enumerate(sample[1:]):\n",
    "            if val > 0.3:\n",
    "                # + 1 because we're enumerating from [1:]\n",
    "                avg_days = (sample.index[idx + 1] - sample.index[idx]).days / 2\n",
    "                return (sample.index[idx + 1] - sample.index[0]).days - avg_days\n",
    "        # If the sample never goes above the threshold\n",
    "        return -1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "dups_zero_to_mal = dups_class.groupby('md5').agg({'antivirus': zero_to_malware}).antivirus.rename('days')\n",
    "dups_zero_to_mal = dups_zero_to_mal[dups_zero_to_mal != -1]\n",
    "# print(dups_zero_to_mal)\n",
    "\n",
    "print('Mean (in days) to go from below the threshold to above:\\t{:.2f}'.format(dups_zero_to_mal.mean()))\n",
    "print('Median to go from below the threshold to above:\\t\\t{:.2f}'.format(dups_zero_to_mal.median()))\n",
    "print('Standard deviation:\\t\\t\\t\\t\\t{:.2f}'.format(dups_zero_to_mal.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Like before, the obtained values are limited by the rebumissions to malwr.com, hence giving some slack between the submission above the threshold and the one before.\n",
    "\n",
    "# Focusing on PE32 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monthly count for PE32 samples\n",
    "crit_pe32 = headers.file_type.map(lambda x: str(x).startswith('PE32 '))\n",
    "pe32 = headers[crit_pe32]\n",
    "pe_monthly_count = pe32.md5.resample('M').count()\n",
    "pe_monthly_count = pe_monthly_count.rename('PE32 samples')\n",
    "plotByMonth(pe_monthly_count,\n",
    "            'pe_monthly_count',\n",
    "            'PE Monthly Count ($\\mu$={:.0f}, $\\Sigma$={})'.format(pe_monthly_count.mean(), pe_monthly_count.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Antivirus classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Keeping this in a separate cell, since it takes 'some' time to exec\n",
    "av_col = pe32.drop_duplicates(subset='md5', keep='last').antivirus\n",
    "av_col = av_col.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "av_col_known = av_col[av_col != -1]\n",
    "av_col_unknown = av_col[av_col == -1]\n",
    "print('Number of known (in VirusTotal) samples:\\t{}'.format(av_col_known.count()))\n",
    "print('Number of unknown samples:\\t\\t\\t{}'.format(av_col_unknown.count()))\n",
    "print('Mean for known samples:\\t\\t\\t\\t{:.2f}'.format(av_col_known.mean()))\n",
    "print('Standard deviation for known samples:\\t\\t{:.2f}'.format(av_col_known.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "av_col_notmal = av_col_known[av_col_known < NOTMAL_THR]\n",
    "av_col_mal = av_col_known[av_col_known > MAL_THR]\n",
    "av_col_grey = av_col_known[(NOTMAL_THR <= av_col_known) & (av_col_known <= MAL_THR)]\n",
    "print('Malware:\\t{} ({:.2f})'.format(av_col_mal.count(), av_col_mal.count()/av_col_known.count()))\n",
    "print('Not malware:\\t{} ({:.2f})'.format(av_col_notmal.count(), av_col_notmal.count()/av_col_known.count()))\n",
    "print('Grey area:\\t{} ({:.2f})'.format(av_col_grey.count(), av_col_grey.count()/av_col_known.count()))\n",
    "\n",
    "# Sanity check\n",
    "assert len(av_col_known) == len(av_col_notmal) + len(av_col_mal) + len(av_col_grey)\n",
    "\n",
    "av_col_notmal = av_col_notmal.resample('M').count().rename('Not malware [0, {})'.format(NOTMAL_THR))\n",
    "av_col_mal = av_col_mal.resample('M').count().rename('Malware ({}, 1]'.format(MAL_THR))\n",
    "av_col_grey = av_col_grey.resample('M').count().rename('Grey area [{}, {}]'.format(NOTMAL_THR, MAL_THR))\n",
    "\n",
    "malware_percent = pd.concat([av_col_mal, av_col_grey, av_col_notmal], axis=1)\n",
    "malware_percent = malware_percent.divide(malware_percent.sum(axis=1), axis=0)\n",
    "plotByMonthPercentage(malware_percent, 'malware_percent', 'Samples classified as malware by percentage (only unique MD5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evolution in duplicated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dups_class = pe32.copy()\n",
    "dups_class['index'] = dups_class.index\n",
    "# Apply the normalization again, to facilitate filtering\n",
    "dups_class['antivirus'] = dups_class['antivirus'].apply(normalize)\n",
    "# Keep only duplicated samples that changed the antivirus classification\n",
    "dups_class = dups_class.drop_duplicates(['md5', 'antivirus'])\n",
    "# Keep only duplicated that changed in time, don't have access to the fulltimestamp, hence same day samples\n",
    "# won't be helpful\n",
    "dups_class = dups_class.drop_duplicates(['md5', 'index'], keep='last')\n",
    "# Keep only duplicates\n",
    "dups_class = dups_class[dups_class.duplicated(subset='md5', keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### From unknown to known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# If the first submission was unknown (-1), calculate the time it took until\n",
    "# sample became known.\n",
    "def unknown_to_known(sample):\n",
    "    if sample[0] == -1:\n",
    "        for idx, val in enumerate(sample[1:]):\n",
    "            if val != -1:\n",
    "                # We take the average between the submission when the sample was known and the\n",
    "                # submission before that, to give the vendors some slack\n",
    "                # + 1 because we're enumerating from [1:]\n",
    "                avg_days = (sample.index[idx + 1] - sample.index[idx]).days / 2\n",
    "                return (sample.index[idx + 1] - sample.index[0]).days - avg_days\n",
    "    else:\n",
    "        return -1.0\n",
    "        \n",
    "dups_unk_to_k = dups_class.groupby('md5').agg({'antivirus': unknown_to_known}).antivirus.rename('days')\n",
    "dups_unk_to_k = (dups_unk_to_k[dups_unk_to_k.map(lambda x: x != -1)]).astype(int)\n",
    "\n",
    "print('Mean (in days) for a sample to become known:\\t{:.2f}'.format(dups_unk_to_k.mean()))\n",
    "print('Standard deviation (in days):\\t\\t\\t{:.2f}'.format(dups_unk_to_k.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tendency in the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculates the tendency for a given sample, based on duplicated submissions\n",
    "# Returns 1 for positive tendency (later submissions have higher classification)\n",
    "# Returns -1 for negative tendency (later submissions have lower classification)\n",
    "# Returns 0 for no tendency (classification between submissions doesn't go above a threshold)\n",
    "# Returns -2 if there aren't enough submissions to check for a tendency\n",
    "def tendency(sample):\n",
    "    from functools import reduce\n",
    "    # If the submissions didn't vary by more than this threshold, no tendency\n",
    "    CHANGE_THR = 0.05\n",
    "    values = []\n",
    "    \n",
    "    for idx, val in sample.iteritems():\n",
    "        if val != -1:\n",
    "            values.append(val)\n",
    "    # Not enough values to check for tendency\n",
    "    if len(values) < 2:\n",
    "        return -2\n",
    "    \n",
    "    diff = [y - x for x, y in zip(values, values[1:])]\n",
    "    # The mean variation is above the threshold\n",
    "    if reduce(lambda x, y: abs(x) + abs(y), diff)/len(diff) > CHANGE_THR:\n",
    "        pos = sum(x > 0 for x in diff)\n",
    "        neg = sum(x < 0 for x in diff)\n",
    "        return 1 if pos > neg else -1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "dups_tendency = dups_class.groupby('md5').agg({'antivirus': tendency}).antivirus.rename('tendency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pos_tend = dups_tendency[dups_tendency == 1]\n",
    "neg_tend = dups_tendency[dups_tendency == -1]\n",
    "\n",
    "print('Number of submissions with positive tendency: {} ({:.2f})'.format(pos_tend.count(), pos_tend.count()/dups_tendency.count()))\n",
    "print('Number of submissions with negative tendency: {} ({:.2f})'.format(neg_tend.count(), neg_tend.count()/dups_tendency.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Average time to classify a malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate the days it took for a sample go from below the threshold\n",
    "# to above the malware threshold. Only includes samples that were known but\n",
    "# not classified as malware\n",
    "def zero_to_malware(sample):\n",
    "    if 0 <= sample[0] < NOTMAL_THR:\n",
    "        for idx, val in enumerate(sample[1:]):\n",
    "            if val > 0.5:\n",
    "                # + 1 because we're enumerating from [1:]\n",
    "                avg_days = (sample.index[idx + 1] - sample.index[idx]).days / 2\n",
    "                return (sample.index[idx + 1] - sample.index[0]).days - avg_days\n",
    "        # If the sample never goes above the threshold\n",
    "        return -1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "dups_zero_to_mal = dups_class.groupby('md5').agg({'antivirus': zero_to_malware}).antivirus.rename('days').astype(int)\n",
    "dups_zero_to_mal = dups_zero_to_mal[dups_zero_to_mal != -1]\n",
    "\n",
    "print('Mean (in days) to go from below the threshold to above: {:.2f}'.format(dups_zero_to_mal.mean()))\n",
    "print('Median to go from below the threshold to above: {:.2f}'.format(dups_zero_to_mal.median()))\n",
    "print('Standard deviation (in days): {:.2f}'.format(dups_zero_to_mal.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
