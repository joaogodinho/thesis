{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LR Big Dataset\n",
    "\n",
    "Trying a LR classifier with the large import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 102382\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import lib.helpers as jcfg_helpers\n",
    "\n",
    "\n",
    "samples = pd.read_csv('data/pe32_imports_labeled.csv')\n",
    "samples['date'] = pd.to_datetime(samples['date'], format='%Y/%m/%d')\n",
    "samples = samples.set_index('date').sort_index()\n",
    "# Filter samples with at least x imports\n",
    "# samples = samples[samples.imports.str.count(';') > 19]\n",
    "goodware = samples[samples.malware == 0]\n",
    "malware = samples[samples.malware == 1]\n",
    "print('Total samples: {}'.format(len(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dataset balancing\n",
    "test_size = 0.1\n",
    "# Find where to cut the array from the size of goodware, which is the limiting factor\n",
    "\n",
    "g_validation = 27000\n",
    "# m_validation = \n",
    "\n",
    "g_training = 3000\n",
    "m_training = .1 * g_training\n",
    "\n",
    "start = math.floor(len(goodware) * (1 - test_size))\n",
    "end = math.floor(len(goodware) * test_size)\n",
    "\n",
    "# assert start + end <= len(goodware)\n",
    "\n",
    "training = pd.concat([goodware[:start], malware[:start]])\n",
    "validation = pd.concat([goodware[start:start + end], malware[start:start + end]])\n",
    "# training, validation = train_test_split(samples, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3450"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation[validation.malware == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Raw LR, w/o Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 22141\n",
      "Malware in training: 31058\n",
      "Goodware in training: 31058\n",
      "Malware in validation: 3450\n",
      "Goodware in validation: 3450\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer Stuff\n",
    "cv_token_pattern = u'[^;]+'\n",
    "min_df=0.0001\n",
    "\n",
    "cv = CountVectorizer(token_pattern=cv_token_pattern, min_df=min_df)\n",
    "train_X = cv.fit_transform(training.imports)\n",
    "train_Y = training.malware\n",
    "test_X = cv.transform(validation.imports)\n",
    "test_Y = validation.malware\n",
    "\n",
    "print('Total features: {}'.format(len(cv.get_feature_names())))\n",
    "print('Malware in training: {}\\nGoodware in training: {}'.format(len(training[training.malware == 1]),\n",
    "                                                                 len(training[training.malware == 0])))\n",
    "print('Malware in validation: {}\\nGoodware in validation: {}'.format(len(validation[validation.malware == 1]),\n",
    "                                                                     len(validation[validation.malware == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Stuff\n",
    "lr = LogisticRegression().fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\t81.39%\n",
      "FP:\t14.56%\n",
      "FN:\t21.83%\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "score = confusion_matrix(test_Y, lr.predict(test_X))\n",
    "fp_rate, fn_rate = jcfg_helpers.calc_ratios(score)\n",
    "\n",
    "print('Score:\\t{:.2f}%\\nFP:\\t{:.2f}%\\nFN:\\t{:.2f}%'.format(\n",
    "    lr.score(test_X, test_Y) * 100, fp_rate * 100, fn_rate * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## LR with Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Malware/Goodware only features\n",
    "\n",
    "Taking the imports that are only present in goodware/malware from 1.5 and use them as features for the LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodware features: 7827\n",
      "Malware features: 153\n"
     ]
    }
   ],
   "source": [
    "# Getting the imports\n",
    "malware_features = pd.Series.from_csv('data/malware_only_features.csv')\n",
    "goodware_features = pd.Series.from_csv('data/goodware_only_features.csv')\n",
    "features = pd.concat([malware_features, goodware_features])\n",
    "# Keep only features that appear in the training\n",
    "# features = features[features.isin(cv.get_feature_names())]\n",
    "features = features[features.isin(cv.get_feature_names())]\n",
    "#features = pd.concat([features, malware_features]).unique()\n",
    "print('Goodware features: {}\\nMalware features: {}'.format(\n",
    "    len(goodware_features[goodware_features.isin(features)]),\n",
    "    len(malware_features[malware_features.isin(features)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 7980\n",
      "Malware in training: 31058\n",
      "Goodware in training: 31058\n",
      "Malware in validation: 3450\n",
      "Goodware in validation: 3450\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer Stuff\n",
    "cv_token_pattern = u'[^;]+'\n",
    "min_df=1\n",
    "\n",
    "cv2 = CountVectorizer(token_pattern=cv_token_pattern, min_df=min_df, vocabulary=features)\n",
    "\n",
    "train_X = cv2.transform(training.imports)\n",
    "train_Y = training.malware\n",
    "test_X = cv2.transform(validation.imports)\n",
    "test_Y = validation.malware\n",
    "\n",
    "print('Total features: {}'.format(len(cv2.get_feature_names())))\n",
    "print('Malware in training: {}\\nGoodware in training: {}'.format(len(training[training.malware == 1]),\n",
    "                                                                 len(training[training.malware == 0])))\n",
    "print('Malware in validation: {}\\nGoodware in validation: {}'.format(len(validation[validation.malware == 1]),\n",
    "                                                                     len(validation[validation.malware == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Stuff\n",
    "lr2 = LogisticRegression().fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 319, 3131],\n",
       "       [   0, 3450]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao/virtual_envs/thesis2/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: divide by zero encountered in long_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\t54.62%\n",
      "FP:\t47.58%\n",
      "FN:\t0.00%\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "score = confusion_matrix(test_Y, lr2.predict(test_X))\n",
    "fp_rate, fn_rate = jcfg_helpers.calc_ratios(score)\n",
    "\n",
    "display(score)\n",
    "display(score[1][1] / score [1][0])\n",
    "print('Score:\\t{:.2f}%\\nFP:\\t{:.2f}%\\nFN:\\t{:.2f}%'.format(\n",
    "    lr2.score(test_X, test_Y) * 100, fp_rate * 100, fn_rate * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Common only features\n",
    "\n",
    "Taking the imports that are only common in goodware/malware from 1.5 and use them as features for the LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Getting the imports\n",
    "common_features = pd.Series.from_csv('data/common_features.csv')\n",
    "features2 = pd.Series(common_features)\n",
    "# Keep only features that appear in the training\n",
    "features2 = features2[features2.isin(cv.get_feature_names())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 16190\n",
      "Malware in training: 2700\n",
      "Goodware in training: 27000\n",
      "Malware in validation: 300\n",
      "Goodware in validation: 3000\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer Stuff\n",
    "cv_token_pattern = u'[^;]+'\n",
    "min_df=1\n",
    "\n",
    "cv3 = CountVectorizer(token_pattern=cv_token_pattern, min_df=min_df, vocabulary=features2)\n",
    "\n",
    "train_X = cv3.transform(training.imports)\n",
    "train_Y = training.malware\n",
    "test_X = cv3.transform(validation.imports)\n",
    "test_Y = validation.malware\n",
    "\n",
    "print('Total features: {}'.format(len(cv3.get_feature_names())))\n",
    "print('Malware in training: {}\\nGoodware in training: {}'.format(len(training[training.malware == 1]),\n",
    "                                                                 len(training[training.malware == 0])))\n",
    "print('Malware in validation: {}\\nGoodware in validation: {}'.format(len(validation[validation.malware == 1]),\n",
    "                                                                     len(validation[validation.malware == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Stuff\n",
    "lr3 = LogisticRegression().fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\t92.97%\n",
      "FP:\t27.33%\n",
      "FN:\t6.06%\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "score = confusion_matrix(test_Y, lr3.predict(test_X))\n",
    "fp_rate, fn_rate = jcfg_helpers.calc_ratios(score)\n",
    "\n",
    "print('Score:\\t{:.2f}%\\nFP:\\t{:.2f}%\\nFN:\\t{:.2f}%'.format(\n",
    "    lr3.score(test_X, test_Y) * 100, fp_rate * 100, fn_rate * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-sided Features\n",
    "\n",
    "Taking imports whose presence is higher in malware/goodware (one-sided imports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate one-sided features\n",
    "cv_token_pattern = u'[^;]+'\n",
    "min_df=1\n",
    "\n",
    "cv4 = CountVectorizer(token_pattern=cv_token_pattern, min_df=min_df)\n",
    "cv4.fit(training.imports)\n",
    "\n",
    "# Get the ocurrences of each feature\n",
    "gtotal = len(training[training.malware == 0])\n",
    "gcount = np.sum(cv4.transform(training[training.malware == 0].imports), axis=0, dtype=int)\n",
    "mtotal = len(training[training.malware == 1])\n",
    "mcount = np.sum(cv4.transform(training[training.malware == 1].imports), axis=0, dtype=int)\n",
    "# Calculate the percentage each feature appears\n",
    "gratio = np.divide(gcount, np.amax(gcount))\n",
    "mratio = np.divide(mcount, np.amax(mcount))\n",
    "# Calculate the difference and ratio\n",
    "diff_ratio = np.absolute(gratio - mratio)\n",
    "feature_ratio = np.divide(diff_ratio, np.amax(diff_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant features: 3118\n"
     ]
    }
   ],
   "source": [
    "# The relevant imports, where the ratio > x\n",
    "features3 = np.array(cv4.get_feature_names(), dtype=str)[np.where(feature_ratio > 0.01)[1]]\n",
    "print('Relevant features: {}'.format(len(features3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 3118\n",
      "Malware in training: 31058\n",
      "Goodware in training: 31058\n",
      "Malware in validation: 3450\n",
      "Goodware in validation: 3450\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer Stuff\n",
    "cv_token_pattern = u'[^;]+'\n",
    "min_df=1\n",
    "\n",
    "# Build bigrams, yeah, don't do this... almost 1M features\n",
    "# features3 = np.append(features3, [\";\".join(i) for i in zip(features3, features3[1:])])\n",
    "cv5 = CountVectorizer(token_pattern=cv_token_pattern, min_df=min_df, vocabulary=features3)\n",
    "# cv5.fit(features3)\n",
    "\n",
    "train_X = cv5.fit_transform(training.imports)\n",
    "train_Y = training.malware\n",
    "test_X = cv5.transform(validation.imports)\n",
    "test_Y = validation.malware\n",
    "\n",
    "print('Total features: {}'.format(len(cv5.get_feature_names())))\n",
    "print('Malware in training: {}\\nGoodware in training: {}'.format(len(training[training.malware == 1]),\n",
    "                                                                 len(training[training.malware == 0])))\n",
    "print('Malware in validation: {}\\nGoodware in validation: {}'.format(len(validation[validation.malware == 1]),\n",
    "                                                                     len(validation[validation.malware == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Stuff\n",
    "lr4 = LogisticRegression().fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\t81.70%\n",
      "FP:\t14.96%\n",
      "FN:\t21.06%\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "score = confusion_matrix(test_Y, lr4.predict(test_X))\n",
    "fp_rate, fn_rate = jcfg_helpers.calc_ratios(score)\n",
    "\n",
    "print('Score:\\t{:.2f}%\\nFP:\\t{:.2f}%\\nFN:\\t{:.2f}%'.format(\n",
    "    lr4.score(test_X, test_Y) * 100, fp_rate * 100, fn_rate * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
