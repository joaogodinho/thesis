{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Reports analysis\n",
    "\n",
    "Understand what should be taken from the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test with some samples\n",
    "from IPython.display import display\n",
    "from lxml import etree, html\n",
    "import lib.report_parsers as jcfg_report_parsers\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "data_dir = 'data/analyses_gz/'\n",
    "samples = ['MjhkYjM1ZjY1YWNkNDQ1Y2FiYmM1M2MwNTI0OGEzYjA',\n",
    "           'MTRiZjc0YTA2MmYwNDA2NDk4MDA1YzU2NzJkY2ZkYjc',\n",
    "           'MzIwZDgzMjY0YjQ5NGQxMjhkZjk1YjE0YTlkNGQ1OTE',\n",
    "           'MzMxZjlkMDljZDA3NDViMThmNzMwOWYwYWNhMGY1MmY',\n",
    "           'YjYxNGFhZTNlZDFkNGI5Yjk1NmEzM2ZlM2EwZWU0YmQ',\n",
    "           'MzMxZjlkMDljZDA3NDViMThmNzMwOWYwYWNhMGY1MmY',\n",
    "           'YTU5ZmNiNzM0OTgyNDQxOTgyMGU5N2MwMGFiYjQzMmI',\n",
    "           'MzYwNjVjZjA4ODgzNGUyOGJiMDMzZWRjNTFlNTcyMDg',\n",
    "           'Mzg3NTIyMTAzZWVmNDQ3OTgzZTM3MDE5NGJlNzQwNzA',\n",
    "           'MzExMzhlYzIyMjZlNGI5ZGE1M2E5MTU3NzdkZTNmOTk',\n",
    "           'NWExYTBjZGVjMzQzNDBlYzg2MjBkM2NjODlhYTcwZWI',\n",
    "           'Zjk1YzcxNDUzNGFiNDliZWFiOWM3NTE3NDE2YThlM2I',\n",
    "           'MTkwZTNmNDRlNWU4NDVlZDllNzY1NWQ0NWE1NjQ3OTk',\n",
    "           'M2Q0OWI2ODJmMTA3NDU5Y2E2MDM3OWNmODlkOWE3OTI',\n",
    "           'OTY0ODgzZGQyNGVmNGEwNTgxMjlkYTA5MzcwMjBlYjI',\n",
    "           'ODg3MzI1MzVkMDBmNGMyNTk0ZTgxM2I1MzMzODMxNGQ',\n",
    "           'NjEwYzNmZDRmYTBiNGQ2NDhmOTcyMjYzY2I3NDdhZWM',\n",
    "           'YjY2YWMxYTdkN2IwNDc5N2E4MDc4YzFlMjM5YzRlNzE',\n",
    "           'NWQ4ZDcyYzNjM2M5NDliYzkwOWJmOWQ0MmJjYThlNTU',]\n",
    "\n",
    "# samples = ['NWExYTBjZGVjMzQzNDBlYzg2MjBkM2NjODlhYTcwZWI']\n",
    "# samples = ['NWQ4ZDcyYzNjM2M5NDliYzkwOWJmOWQ0MmJjYThlNTU']\n",
    "# samples = ['ODIyNjI1MjdiOTFhNDY1ZjljZDBhNmE0ODIyMTc0YzY']\n",
    "# samples = ['OTNkNGFkMTAyYjg1NDc4MWExNjY2MzQ5OTI3MjVjM2I']\n",
    "# samples = ['N2NlNzIwM2Q3YjYyNDA0MzkxNjBhYWQ1OGI1ZWEzNzU']\n",
    "# samples = ['MjhkYjM1ZjY1YWNkNDQ1Y2FiYmM1M2MwNTI0OGEzYjA']\n",
    "# Keys\n",
    "# samples = ['YWRlNzgyMzk2ZDAwNDQzMmE3Y2ZjM2VhYzQ5OWFkZjU']\n",
    "\n",
    "def parse_report(sample, location):\n",
    "    \"\"\"\n",
    "        Takes a sample file, loads it and parses the report\n",
    "    \"\"\"\n",
    "    SIZE_LIMIT = 10000000\n",
    "    location = location + '/' if location[-1] != '/' else location\n",
    "    func_list = list(filter(lambda x: x.startswith('extract_'), dir(jcfg_report_parsers)))\n",
    "    \n",
    "    \n",
    "    with gzip.open(location + sample) as gz_file:\n",
    "        content = gz_file.read().decode('utf8')\n",
    "    \n",
    "    content = jcfg_report_parsers.remove_whitespaces(content)\n",
    "    func_cutpoints = jcfg_report_parsers.generate_func_cutpoints(content)\n",
    "    # Check if any section is over 10MB, otherwise\n",
    "    # lxml can take it anyway\n",
    "    report = dict()\n",
    "    for idx, pair in enumerate(func_cutpoints[1:]):\n",
    "        if pair[1] > SIZE_LIMIT:\n",
    "            # Section to parse is the one before the one being compared\n",
    "            func_cutpoints[idx] = (func_cutpoints[idx][0] + '_huge', func_cutpoints[idx][1])\n",
    "        # if func_cutpoints[idx][0] == 'extract_mutexes':\n",
    "            # func_cutpoints[idx] = ('extract_mutexes_huge', func_cutpoints[idx][1])\n",
    "\n",
    "    # Returns either str if manual parsing or etree \n",
    "    input_type = lambda name, content: content if '_huge' in name else etree.HTML(content)\n",
    "    for func, cutpoint in func_cutpoints:\n",
    "        content = content[cutpoint:]\n",
    "        # Turn the string into a function and call it with correct input\n",
    "        result = getattr(jcfg_report_parsers, func)(input_type(func, content))\n",
    "        # When saving we don't need the _huge call\n",
    "        report[func.replace('_huge', '')] = result\n",
    "\n",
    "    return (sample, report)\n",
    "\n",
    "\n",
    "import json \n",
    "from os import walk\n",
    "\n",
    "#(_, _, reports) = next(walk(data_dir))\n",
    "# for sample in reports:\n",
    "#    parse_report(sample, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12847684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tasks\n",
    "from celery import group\n",
    "\n",
    "samples = ['NWExYTBjZGVjMzQzNDBlYzg2MjBkM2NjODlhYTcwZWI',]\n",
    "\n",
    "#reports = []\n",
    "#for sample in samples:\n",
    "#    print(sample)\n",
    "    # Load bunch of gz's into memory\n",
    "#    reports.append(sample)\n",
    "\n",
    "# Parse them\n",
    "# print(len(reports))\n",
    "# jobs = group([tasks.extract_from_report.s(func_list, rep) for rep in reports])\n",
    "# result = jobs.apply_async()\n",
    "# result.join()\n",
    "                      \n",
    "# display(len(result.get()))\n",
    "\n",
    "# Read around 10GB to memory\n",
    "CONTENT_SIZE = 1000000 * 1000 * 0.01\n",
    "content_size = 0\n",
    "content_batch = []\n",
    "data_dir = 'data/analyses_gz/'\n",
    "output = 'data/extracted/'\n",
    "for sample in samples:\n",
    "    with gzip.open(data_dir + sample) as gz_file:\n",
    "        content = jcfg_report_parsers.remove_whitespaces(gz_file.read().decode('utf8'))\n",
    "        content_size += len(content)\n",
    "        content_batch.append((sample, content))\n",
    "        display(content_size)\n",
    "    if content_size >= CONTENT_SIZE:\n",
    "        # Fire away\n",
    "        jobs = group([tasks.extract_from_report.s(link, content) for link, content in content_batch])            \n",
    "        # Wait for workers to finish\n",
    "        result = jobs.apply_async()\n",
    "        result.join()\n",
    "        for r in result.get():\n",
    "            with open(output + r[0], 'w') as file:\n",
    "                file.write(json.dumps(r[1]))\n",
    "        content_size = 0\n",
    "        content_batch = []\n",
    "    \n",
    "# Fire away\n",
    "jobs = group([tasks.extract_from_report.s(link, content) for link, content in content_batch])            \n",
    "# Wait for workers to finish\n",
    "result = jobs.apply_async()\n",
    "result.join()\n",
    "for r in result.get():\n",
    "    with open(output + r[0], 'w') as file:\n",
    "        file.write(json.dumps(r[1]))\n",
    "print(result.get())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
